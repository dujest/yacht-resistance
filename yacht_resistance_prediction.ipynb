{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Residuary Resistance of Sailing Yachts\n",
    "\n",
    "1. **Frame the problem and look at the big picture**\n",
    "2. **Get the Data**\n",
    "3. **Data Insights**\n",
    "4. **Prepare the Data for ML Algorithms**\n",
    "5. **Select and Train a Model**\n",
    "6. **Model Fine Tuning**\n",
    "7. **Test Set Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(\"Python version:\", sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(\"scikit-learn version:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00243/\"\n",
    "DATA_URL = DOWNLOAD_ROOT + \"yacht_hydrodynamics.data\"\n",
    "DATA_PATH = os.path.join(\"datasets\", \"yacht\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(data_url=DATA_URL, data_path=DATA_PATH):\n",
    "    if not os.path.isdir(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    full_data_path = os.path.join(data_path, \"yacht_hydrodynamics.data\")\n",
    "    urllib.request.urlretrieve(data_url, full_data_path)\n",
    "\n",
    "fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = [\"Centre_of_Buoyancy\", \"Prismatic_Coefficient\", \"Length/Displacement_Ratio\", \"Beam/Draft_Ratio\", \n",
    "           \"Length/Beam_Ratio\", \"Froude_Number\", \"Residuary_Resistance\"]\n",
    "\n",
    "def load_data(data_path=DATA_PATH):\n",
    "    full_data_path = os.path.join(data_path, \"yacht_hydrodynamics.data\")\n",
    "    return pd.read_table(full_data_path, sep='\\s+', names=columns)\n",
    "\n",
    "yacht = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the top ten rows\n",
    "yacht.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a quick description of the data:\n",
    "# the total number of rows, each attribute's type, and the number of non-null values\n",
    "yacht.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 308 instances in the dataset, which means that it is fairly small by ML standards, but the aim of this project is to apply machine learning in the domain of naval engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of null values for each attribute\n",
    "yacht.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22 sailing yacht hull forms were tested at the same speeds within the speed range 0.125 - 0.450\n",
    "yacht[\"Froude_Number\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a summary of the numerical attributes\n",
    "yacht.describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The std row shows the standard deviation, which measures how dispersed the values are.\n",
    "\n",
    "The 25%, 50% and 75% rows show the corresponding percentiles, which indicate the values below which a given percentage of observations in a group of observations fall. \n",
    "\n",
    "For example, 50% of the hull forms have the residuary resistance lower than 3.065, while the max value is 62.42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "mpl.rc(\"axes\", labelsize=14, titlesize=14)\n",
    "mpl.rc(\"xtick\", labelsize=12)\n",
    "mpl.rc(\"ytick\", labelsize=12)\n",
    "\n",
    "# for each attribute, show the number of instances (on the vertical axis) that have a given value range (on the horizontal axis)\n",
    "yacht.hist(bins=3, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht.plot(kind=\"scatter\", x=\"Froude_Number\", y=\"Residuary_Resistance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The residuary resistance grows eponentially with increase of the velocity.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht[\"Length/Displacement_Ratio\"].value_counts() / len(yacht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# stratified sampling based on the length/displacement ratio\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(yacht, yacht[\"Length/Displacement_Ratio\"]):\n",
    "    strat_train_set = yacht.loc[train_index]\n",
    "    strat_test_set = yacht.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht_features = strat_train_set.drop(\"Residuary_Resistance\", axis=1)\n",
    "yacht_labels = strat_train_set[\"Residuary_Resistance\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = yacht.corr()\n",
    "\n",
    "corr_matrix[\"Residuary_Resistance\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prepare the Data for ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(yacht, test_size=0.2, random_state=42)\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# stratified sampling based on the length/displacement ratio\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(yacht, yacht[\"Length/Displacement_Ratio\"]):\n",
    "    strat_train_set = yacht.loc[train_index]\n",
    "    strat_test_set = yacht.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht_features = strat_train_set.drop(\"Residuary_Resistance\", axis=1)\n",
    "yacht_labels = strat_train_set[\"Residuary_Resistance\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_incomplete_rows = yacht_features[yacht_features.isnull().any(axis=1)]\n",
    "sample_incomplete_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = \"Centre_of_Buoyancy\", \"Prismatic_Coefficient\", \"Length/Displacement_Ratio\"\n",
    "# get the column indices\n",
    "L_bc_ix, Cp_ix, L_D_ratio_ix = [yacht_features.columns.get_loc(c) for c in column_names]\n",
    "L_bc_ix, Cp_ix, L_D_ratio_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# add two more attributes:\n",
    "# Lbc_Cp_ratio - center of bouyancy/prismatic coefficient ratio\n",
    "# LD_Cp_ratio - (length/displacement ratio)/prismatic coefficient ratio\n",
    "class CombinedAtributeAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_LD_Cp_ratio=True):\n",
    "        self.add_LD_Cp_ratio = add_LD_Cp_ratio\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        Lbc_Cp_ratio = X[:, L_bc_ix] / X[:, Cp_ix]\n",
    "        if self.add_LD_Cp_ratio:\n",
    "            LD_Cp_ratio = X[:, L_D_ratio_ix] / X[:, Cp_ix]\n",
    "            return np.c_[X, Lbc_Cp_ratio, LD_Cp_ratio]\n",
    "        else:\n",
    "            return np.c_[X, Lbc_Cp_ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_adder = CombinedAtributeAdder(add_LD_Cp_ratio=True)\n",
    "yacht_extra_attr = attribute_adder.transform(yacht_features.values)\n",
    "\n",
    "yacht_extra_attr = pd.DataFrame(yacht_extra_attr,\n",
    "                                    columns=list(yacht_features.columns)\n",
    "                                    +[\"Centre_of_Buoyancy/Prismatic_Coefficient_Ratio\", \"Length_Displacement/Prismatic_Coefficient_Ratio\"],\n",
    "                                    index=yacht_features.index)\n",
    "\n",
    "yacht_extra_attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht_extra_attr.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "yacht_pipeline = Pipeline([\n",
    "            (\"attributes_adder\", CombinedAtributeAdder()),\n",
    "            (\"features_scaler\", StandardScaler()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht_features_tr = yacht_pipeline.fit_transform(yacht_features.values)\n",
    "\n",
    "yacht_features_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Select and Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(yacht_features_tr, yacht_labels)\n",
    "yacht_predictions = lin_reg.predict(yacht_features_tr)\n",
    "\n",
    "lin_mse = mean_squared_error(yacht_labels, yacht_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(model, features, labels):\n",
    "    features_train, features_val, labels_train, labels_val = train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(features_train) + 1):\n",
    "        model.fit(features_train[:m], labels_train[:m])\n",
    "        train_predict = model.predict(features_train[:m])\n",
    "        val_predict = model.predict(features_val)\n",
    "        train_errors.append(mean_squared_error(train_predict, labels_train[:m]))\n",
    "        val_errors.append(mean_squared_error(val_predict, labels_val))\n",
    "    \n",
    "    plt.plot(np.sqrt(train_errors), 'r-.', linewidth=3, label='train')\n",
    "    plt.plot(np.sqrt(val_errors), 'b-', linewidth=3, label='val')\n",
    "    plt.legend(loc='upper right', fontsize=14)\n",
    "    plt.xlabel(\"Training set size\", fontsize=14)\n",
    "    plt.ylabel(\"RMSE\", fontsize=14)\n",
    "    print(\"Training error:\", np.sqrt(train_errors[-1]))\n",
    "    print(\"Vallidation error:\", np.sqrt(val_errors[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(lin_reg, yacht_features_tr, yacht_labels)\n",
    "plt.axis([0, 220, 0, 20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polynomial_regression = Pipeline([\n",
    "        (\"attributes_adder\", CombinedAtributeAdder()),\n",
    "        (\"poly_features\", PolynomialFeatures(degree=5, include_bias=False)),\n",
    "        (\"features_scaler\", StandardScaler()),\n",
    "        (\"lin_reg\", LinearRegression()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(polynomial_regression, yacht_features.values, yacht_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(elastic_net, yacht_features_tr, yacht_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stohastic Gradient Descent - Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from copy import deepcopy\n",
    "\n",
    "features_train, features_val, labels_train, labels_val = train_test_split(yacht_features.values, yacht_labels.ravel(), test_size=0.2, random_state=42)\n",
    "\n",
    "polynomial_scaler = Pipeline([\n",
    "        (\"attributes_adder\", CombinedAtributeAdder()),\n",
    "        (\"poly_features\", PolynomialFeatures(degree=5, include_bias=False)),\n",
    "        (\"features_scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "features_train_poly_scaled = polynomial_scaler.fit_transform(features_train)\n",
    "features_val_poly_scaled = polynomial_scaler.transform(features_val)\n",
    "\n",
    "sgd_reg = SGDRegressor(max_iter=1, tol=-np.infty, warm_start=True,\n",
    "                       penalty=None, learning_rate=\"constant\", eta0=0.0005, random_state=42)\n",
    "\n",
    "n_epochs = 500\n",
    "train_errors, val_errors = [], []\n",
    "\n",
    "minimum_val_error = float(\"inf\")\n",
    "best_epoch = None\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    sgd_reg.fit(features_train_poly_scaled, labels_train)\n",
    "    y_train_predict = sgd_reg.predict(features_train_poly_scaled)\n",
    "    train_errors.append(mean_squared_error(labels_train, y_train_predict))\n",
    "\n",
    "    y_val_predict = sgd_reg.predict(features_val_poly_scaled)\n",
    "    val_error = mean_squared_error(labels_val, y_val_predict)\n",
    "    val_errors.append(val_error)\n",
    "\n",
    "    if val_error < minimum_val_error:\n",
    "        minimum_val_error = val_error\n",
    "        best_epoch = epoch\n",
    "        best_model = deepcopy(sgd_reg)\n",
    "\n",
    "best_train_epoch = np.argmin(train_errors)\n",
    "best_train_rmse = np.sqrt(train_errors[best_train_epoch])\n",
    "\n",
    "best_val_epoch = np.argmin(val_errors)\n",
    "best_val_rmse = np.sqrt(val_errors[best_val_epoch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.annotate('Best model',\n",
    "            xy=(best_val_epoch, best_val_rmse),\n",
    "            xytext=(best_val_epoch, best_val_rmse + 1),\n",
    "            ha=\"center\",\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "            fontsize=16,\n",
    "            )\n",
    "\n",
    "plt.plot([0, n_epochs], [best_val_rmse, best_val_rmse], 'k:', linewidth=2)\n",
    "plt.plot(np.sqrt(val_errors), 'b-', linewidth=3, label=\"Validation set\")\n",
    "plt.plot(np.sqrt(train_errors), 'r--', linewidth=2, label=\"Training set\")\n",
    "plt.legend(loc=\"upper right\", fontsize=14)\n",
    "plt.axis([0, 500, 0, 5])\n",
    "plt.xlabel(\"Epoch\", fontsize=14)\n",
    "plt.ylabel(\"RMSE\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print(\"Training error:\", best_train_rmse)\n",
    "print(\"Vallidation error:\", best_val_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel=\"poly\", C=100, gamma=\"auto\", degree=3, epsilon=0.1, coef0=1)\n",
    "svm_reg.fit(yacht_features_tr, yacht_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_yacht_predictions = svm_reg.predict(yacht_features_tr)\n",
    "svm_mse = mean_squared_error(yacht_labels, svm_yacht_predictions)\n",
    "svm_rmse = np.sqrt(svm_mse)\n",
    "svm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(svm_reg, yacht_features_tr, yacht_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(yacht_features_tr, yacht_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_yacht_predictions = tree_reg.predict(yacht_features_tr)\n",
    "tree_mse = mean_squared_error(yacht_labels, tree_yacht_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(tree_reg, yacht_features_tr, yacht_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "tree_mse_scores = cross_val_score(tree_reg, yacht_features_tr, yacht_labels,\n",
    "                        scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "tree_rmse_scores = np.sqrt(-tree_mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_reg.fit(yacht_features_tr, yacht_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_yacht_predictions = forest_reg.predict(yacht_features_tr)\n",
    "forest_mse = mean_squared_error(yacht_labels, forest_yacht_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(forest_reg, yacht_features_tr, yacht_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_mse_scores = cross_val_score(forest_reg, yacht_features_tr, yacht_labels,\n",
    "                        scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "forest_rmse_scores = np.sqrt(-forest_mse_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [100, 250, 500], 'max_features': [4, 6, 8]},\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=10,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "                           \n",
    "grid_search.fit(yacht_features_tr, yacht_labels)                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best hyperparameter combination found:', grid_search.best_params_)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_score = grid_search.cv_results_\n",
    "for mean_score, params in zip(grid_search_score[\"mean_test_score\"], grid_search_score[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(low=50, high=250),\n",
    "    'max_features': randint(low=5, high=8),\n",
    "}\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distributions,\n",
    "                                n_iter=10, cv= 10, scoring='neg_mean_squared_error', random_state=42)\n",
    "\n",
    "rnd_search.fit(yacht_features_tr, yacht_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_score = rnd_search.cv_results_\n",
    "for mean_score, params in zip(rnd_search_score[\"mean_test_score\"], rnd_search_score[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"R_rs\", axis=1)\n",
    "y_test = strat_test_set[\"R_rs\"].copy()\n",
    "\n",
    "X_test_tr = yacht_pipeline.transform(X_test.values)\n",
    "final_predictions = final_model.predict(X_test_tr)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print('Test set RMSE:', final_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "                         loc=squared_errors.mean(),\n",
    "                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_percentage = (abs(y_test - final_predictions) * 100 )/y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_table = np.block([[final_predictions.round(2)], [y_test], [error_percentage.round(2)]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(error_table, columns=[\"Predicted values\", \"Correct values\", \"Error (%)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_percentage.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the generalization error that the model makes\n",
    "print(\"The mean error:\", error_percentage.mean().round(2), \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ml-yrp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4be6c2bb49d24515f1650ecf25b3e93e0cda5b5fbe8c944f724117236b6fd181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
